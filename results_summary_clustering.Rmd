---
title: "Cluster Analysis Summary"
author: "Krista DeStasio"
date: '2019-03-27'
output:
  pdf_document:
    toc: yes
    toc_depth: '3'
  word_document:
    toc: yes
    toc_depth: '3'
  html_document:
    toc: yes
    toc_depth: 3
    toc_float: no
tags:
- clustering
- tutorials
- how to
- R
- k-means
- hierarchical clustering
- unsupervised learning
---

```{r include=FALSE}
#Clear workspace
rm(list = ls()) 

# Set paths and working directory
working_dir = '~/Dropbox/collaborations/hunter_college/hc_analysis/'
setwd(working_dir)
# Load objects from the clustering analysis
load(paste0(working_dir, 'clustering_objects.Rda'))
load(paste0(working_dir, 'clustering_model_kmeans2.Rda'))
load(paste0(working_dir, 'descriptives_tables.Rda'))

# Install and load required packages
list.of.packages <- c('janitor', 'kernlab', 'dplyr', 'ggplot2', 'tidyr', 'knitr', 'cluster', 'flexclust')
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])] 
if (length(new.packages)) install.packages(new.packages, repos = "http://cran.us.r-project.org")
lapply(list.of.packages, library, character.only = TRUE)

# Knit options
knitr::opts_chunk$set(echo = FALSE, eval = TRUE)
```

# 1. Summary
## 1.1 Cluster Formation

*Identification of similarity-based groups in the dot probe data.*  

The aim of this clustering analysis is to identify similar sub-groups in the anxiety dot probe based on performance measures listed in Table 1. We used several clustering algorithms. Clustering algorithms are designed to group data based on their similarity or dissimilarity (e.g. distance in euclidian space). Three clustering algorithms are applied to the dot-probe measures: spectral clustering (connectivity), k-means clustering (compactness), and hierarchical clustering (pair-wise similarity). These partitioning and divisive algorithms are selected as they are well suited to numerical data (Halkidi, 2001). Euclidian distance is used as the distance measure for all three algorithms in out analyses. Bottom-up hierarchical clustering assigns each point to it's own cluster, then measures the pairwaise similarity between observations. The hierarchical methods we will use are the largest similarity (complete linkage) and average similarity (average linkage) between points. These methods iteratively combine clusters into fewer clusters based on the distance between them, creating a branching structure, until there is only one parent cluster under which the subclusters are nested (Cichosz, 2015). K-means is a partition based clustering algorithm that groups data points by their distance from the mean of that cluster's objects (Nerurkar et al., 2018). Spectral clustering represents the data as a similarity graph in which data poionts are nodes and the distances between them are weighted edges (Von Luxburg, 2007). Unlike hierarchical clustering, both k-means and spectral clustering require a priori specification of the number of clusters.  


---

**Table 1. Dot Probe Performance Measures.** *Those measures not included in cluster identification describe information inherent in the other variables.*  

Variable name      | Description | Included in analysis?
------------------ |------------ | :---------------------: 
`rt_neutral_nt`| Average RT on all neutral trials | YES
`rt_threat_nt`| Average RT on all threat trials | YES
`rt_baseline`| Average RT on baseline trials where two neutral faces appear and there is no competition for attention between threat and neutral faces; These trials appear randomly throughout the task | YES
`mean_pos`| mean of positive trial-level threat bias scores | YES
`mean_neg`| mean of negative trial-level threat bias scores  | YES
`peak_pos`| highest positive trial-level threat bias score | YES
`peak_neg`| highest negative trial-level threat bias score  | YES
`rt_outliers`| # of trials considered to be outliers based on the following criteria (RTs faster than 150 ms or slower than 2000 ms; any trial RT that was +/- 3 SD from the personâ€™s mean RT for that trial type) | NO
`variability`| absolute value of the distance across all trial-level threat bias scores / number of pairs | YES  

#2. Implementation of cluster model for cluster membership prediction

*Using the created model for prediction of group membership in new data.*  

A k-means clustering model with 2 centroids, developed on the data provided us, is recommended for out of sample prediction of group membership. The preferred model was selected based on internal criteria, based on an evaluation of properties of the clusters themselves, and relative citeria, based on an evaluation of the clustering solutions of an algorithm compared to solutions by the same algorithm with different parameters (Halkidi, 2001).  

To assign group membership for new data, one may calculate the observation's distance from each cluster centroid and assign the observation to the cluster with the nearest centroid. Executuion of this comparison should be done after the new data are preprocessed in the same way that the model training data were preprocessed (see section 3).

1. The new data will need to be preprocessed in the same way as the training data
    - Remove participants with an accuracy of less than .80 (Do in the same way as was done for the training data)
    - Read in and subset the data to include only those dot probe measures indicated 'YES' in Table 1.
    ```
    new_data <- clean_names(readxl::read_excel(path_to_data_file)) 
    data <- subset(new_data, 
        select = c(rt_neutral_nt, 
                    rt_threat_nt, 
                    rt_baseline, 
                    mean_pos, 
                    mean_neg, 
                    peak_pos, 
                    peak_neg))
    ```
    - Omit observations with missing values
    - Check for zero or near zero variance
    ```
    caret::nearZeroVar(data, saveMetrics = TRUE)
    ```
    - Check that there are no linear dependencies of variables (there should not be as the same measures are to be used in the new data as in the initial data used to train the model)
    ```
    caret::findLinearCombos(data)
    ```
    - Standardize the continuous variables (mean = 0, sd = 1)
    ```
    data_scaled <- scale(data)
    ```
    - Use PCA to reduce the data to 2 dimensions
    ```
    # run pca
    data_pca <- prcomp(x = data_scaled)
    # Subset to include only 2 components
    pca2 <- data_pca$x[,1:2]
    ```

2. Load the model created from the training data
    ```
    load("path/to/model/clustering_model_kmeans2.Rda")
    ```

3. Assign new observations to clusters based on the 2-cluster k-means solution
    ```
    predicted_cluster_membership <- predict(kmeans_kcca, newdata = pca2)
    ```
    - The resulting vector indicates cluster membership. An observation is assigned to the cluster with the closest mediod based on euclidean distance. This vector can be bound to the data frame and used for analyses.  For example:
    
    ```
    cbind(predicted_cluster_membership, new_data)
    aov(outcome_measure ~ predicted_cluster_membership + Error(subject_id/PICK_A_CLUSTERING_METHOD), data = new_data)
    ```

For additional details about the R environment and preprocessing, as well for a comparison of the models tested, see Section 3.  

# 3. Cluster Analysis Details
## 3.1 Environment

*All analyses were conducted using R (R Core Team, 2018).* 

```
platform       x86_64-apple-darwin15.6.0   
arch           x86_64                      
os             darwin15.6.0                
system         x86_64, darwin15.6.0        
status                                     
major          3                           
minor          5.1                         
year           2018                        
month          07                          
day            02                          
svn rev        74947                       
language       R                           
version.string R version 3.5.1 (2018-07-02)
nickname       Feather Spray  
```

## 3.2 Preprocessing

Outliers were already removed from the data by our collaborators based on the percentage of trials that were answered correctly. Participants with an accuracy of .80 or greater are included in the dataset. 

### 3.2.1 Variance, Colinearity, and Measurement Scale

All variables were checked for zero or near zero variance and no issues were found. The dataset was checked for variables that are linear combinations of other variables with the intention to remove those indicated. None of the vairables included in the cluster analysis are colinear. Because clustering is sensitive to differences in the measurement scales of data, the features were standardized (*M*=0, *sd*=1).  

### 3.2.2 Dimensionality Reduction 

Principal Components Analysis (PCA), a dimensionality reduction technique, was used as a precursor to clustering to decresase overfitting and to make the models more inerpretable (Zha, et al., 2002; Ding & He, 2004). PCA projects high dimensional data onto a lower dimensional sub-space and rotates data to mazimize variance in the new axes. The components are then listed in order of decreasing variance with the first component accounting for the greatest proportion of feature variance. Based on the cumulative proportion of variance (see Table 2) and the location of the elbow in the PCA scree plot (see Figure 1), data reduced to 2 principal components were used to develop the clustering models.  

```{r}
kable(pca_summary$importance, digits = 2, 
      caption = 'Table 2. Variance Accounted For By Each Principal Component')

# Plot the variance explained for each principal component
prop_var_each <- pca_scaled$sdev^2 / sum(pca_scaled$sdev^2)
plot(prop_var_each, xlab = "Principal Component",
     ylab = "Proportion of Variance Explained",
     ylim = c(0,1), type = "b",
     main = 'Figure 1. Cumulative Proportion of Variance \nby Number of Components')
```

## 3.3 Model Comparison
K-means, spectral clustering, and hierarchical clustering algorithms were used to explore the structure of the dot probe data. Model fit metrics are reported in the summary tables (Tables 3 & 4) for Hierarchical and K-means clustering algorithms. Spectral clustering results are not included as the models performed poorly. For the full analysis with all models, see the `analysis_clustering.Rmd` file. Models are evaluated based on:  

- Cluster compactness
    - Aberage distance within clusters (lower = better)
- Cluster separation
    - Average distance between clusters (higher = better)
- Cluster distance (compactness & separation)
    - Silhouette coefficient (closer to 1 means well classified, near 0 means observations are between clusters, negative means observations are likely misclassified)
    - Number of observations with a negative sillhuoette
    
The K-means 2 cluster solution is preferred because in comparison to the other models, it does not have any clusters that are extremely small, it has a relatively high silhouette coefficient (per cluster and average) with few misclassifications based on the number of observations with a negative sillhuoette, and comparatively good between and within cluster average distances. Furthermore, the 2 cluster solution produces results that are relatiely interpretable based on the an examination of the variables by cluster (see Figure 4 and Table 5.).    
    
```{r}
kable(fit_df, digits = 2, row.names = FALSE,
      caption = "Table 3. Evaluation of Cluster Goodness of Fit for K-means")
kable(clusstats_df, digits = 2, row.names = FALSE,
      caption = "Table 4. Cluster Descriptions for K-means")

```

**Figure 2. K-means 2 cluster Plot**    
![](/Users/kristadestasio/Dropbox/collaborations/hunter_college/hc_analysis/Figs/unnamed-chunk-1-1.png)  

**Figure 3. K-means 2 cluster Silhouette Plot Plot**  

![](/Users/kristadestasio/Dropbox/collaborations/hunter_college/hc_analysis/Figs/unnamed-chunk-1-3.png)  


**Figure 4. Plot of Variable Means by Cluster Based on K-means Clustering**  
![](/Users/kristadestasio/Dropbox/collaborations/hunter_college/hc_analysis/Figs/unnamed-chunk-10-2.png)  

```{r}
kable(aggregate(data_matrix_aim1, 
                by = list(cluster = km_k2_res$cluster), mean), 
      digits = 2,
      caption = "Table 5. K-means 2 Cluster Solution: Raw Score Means by Cluster")
```

# 4. Additional Clarification
Looking at the K-means plots, we see that the 2 cluster solution (Figure 5) produces one cluster (cluster 2) with observations that tend to be closer to zero, whereas cluster 1 observations tend to to be more greatly negative or positive. The 3 cluster K-means solution (Figure 6), generates a third cluster (cluster 1 of the 3 cluster solution) by pulling some observations from the other 2 clusters without adding any new observations to them.   

**Figure 5. **  
![](/Users/kristadestasio/Dropbox/collaborations/hunter_college/hc_analysis/Figs/kmeans plot var means by cluster-1.png)

**Figure 6. **  
![](/Users/kristadestasio/Dropbox/collaborations/hunter_college/hc_analysis/Figs/kmeans plot var means by cluster-2.png)  

We can see that this is the vase by examining the `table()` output included below.  

```{r}
table(km_k2_res$cluster)
table(km_k3_res$cluster)
table(km_k2_res$cluster, km_k3_res$cluster)
```

The clusters themselves are simply a representation of how the data are grouped together. There is no meaning inherent in the clusters. This is where your expertise regarding the clinical literature and this task in particular should inform the decision of whether to use a 2 or 3 cluster solution. To me, a two cluster solution seems the most straight forward as the clusters seem to represent slower responders with more extreme peak and mean threat bias scores (cluster 1) and faster responders with less extreme threat bias scores (cluster 2). However, I do not have the in-depth knowledge of the dot probe to make an informed decision as to whether a 2 or 3 cluster solution makes more sense _for this task_. Either solution will work for out of sample prediction, at this point, it's a matter of which grouping makes the most sense based on your understanding of the task and what you want to test. My one recommendation would be to pre-register on OSF or elsewhere which clustering solution you choose to implement (2 or 3 centroids with K-means) and why as it is a subjective decision and preregistration will likely help alleviate reviewer concerns during review.  


