---
title: 'Hunter College Data: Clustering Analysis'
author: "Krista DeStasio"
date: "11/06/2018"
output:
  word_document:
    toc: yes
    toc_depth: '3'
  html_document:
    toc: yes
    toc_depth: 3
    toc_float: no
---

```{r setup, include=FALSE}
# Clear workspace
rm(list = ls()) 

# Set paths and working directory
working_dir = '~/Dropbox/collaborations/hunter_college/hc_analysis/'
path_datafile = paste0(working_dir, '/data/N=844_FINAL_Traditional metrics_Trial Level metrics_questionnaires (n=837)_6.16.18.xlsx')
setwd(working_dir)

# Install and load required packages
list.of.packages <- c('janitor')
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])] 
if (length(new.packages)) install.packages(new.packages, repos = "http://cran.us.r-project.org")
lapply(list.of.packages, library, character.only = TRUE)

# Knit options
knitr::opts_chunk$set(echo = TRUE)
```

# Feedback from demo
**Suggestions**
- if have really high error (if the groups don't generalize well training to test) then what's the plan. Going to use different clustering algorithm? (random walk? classification and regression tree?) Network analysis tutorial from data science.
- What other unsupervised learning methods might work?  
    - [Density-Based Spatial Clustering of Applications with Noise (DBSCAN)](https://www.datascience.com/blog/k-means-alternatives) or [Hierarchical (H)DBSCAN]https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html
    - [Agglomerative clustering/Ward hierarchical clustering](https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering)
    - [Gaussian mixtures](https://scikit-learn.org/stable/modules/mixture.html#mixture): **No. Soft clustering.**
    
- What is the metric of how well it's doing?  
    - Silhouette Coefficient (?)
    - Calinski-Harabaz Index (?)
- Identify ANOVA error term. See https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-how-can-i-determine-the-correct-error-term-in-an-anova/

*Tracy writes:* "As I see it our first goal is testing whether distinct attention bias grouping emerge from the dot probe and questionnaire data using classification algorithms. Once these groups are identified, we can look at whether these are treatment-relevant subgroups (i.e., ABMT training is more effective for one group versus the other)."  

"examine the conditions under which ABMT efficacy is boosted or disrupted, and to identify individual differences that impact training gains"

A search for moderators that machine learning may be sensitive enough to detect.  

## Introduction
The primary aim of this analysis is to identify whether meaningful subgroups emerge from the anxiety dot probe. If meaningful subgroups do emerge, our secondary aim is to whether cluster membership relates to anxiety as measured by the State-Trait Anxiety Inventory (STAI). To test this aim, group membership will be entered as an independent variable into a between-subjects ANOVA with STAI trait anxiety scores as the dependent measure of interest. This is done with the eventual goal of predicting treatment trajectories in an unrelated sample of ABMT recipients.  

## Methods
All analyses will be conducted using R (R Core Team, 2018). I will run both a spectral clustering analysis (connectivity) and a k means cluster analysis (compactness) to identify subgroups within the Anxiety Dot Probe measures as these approaches are well suited to numeric data. Prior to any analysis, the data will be split into development (80%) and holdout (20%) sets, then the development set will be further split into training (70%) and testing (30%) sets. 


Dot Probe measures that will be included in the analysis include:  

- `rt_neutral_nt`: Average RT on all neutral trials  
- `rt_threat_nt`: Average RT on all threat trials  
- `rt_baseline`: Average RT on baseline trials where two neutral faces appear and there is no competition for attention between threat and neutral faces; These trials appear randomly throughout the task  
- `rt_outliers`: # of trials considered to be outliers based on the following criteria (RTs faster than 150 ms or slower than 2000 ms; any trial RT that was +/- 3 SD from the person’s mean RT for that trial type)  
- `mean_pos`: mean of positive trial-level threat bias scores  
- `mean_neg`: mean of negative trial-level threat bias scores      
- `peak_pos`: highest positive trial-level threat bias score
- `peak_neg`: highest negative trial-level threat bias score           
- `variability`: absolute value of the distance across all trial-level threat bias scores / number of pairs 

## Data preprocessing 
Outliers were already removed from the data by our collaborators based on the percentage of trials that were answered correctly. Participants with an accuracy of .80 or greater are included in the dataset. There should be no missing data for the dot probe measures as the included metrics can be computed for anyone who completed the task.

The training, testing, and holdout sets will be independently preprocessed. The datasets will be checked for variables that are linear combinations of other variables and those indicated will be removed. Variables will be standardized using the `scale()` function to mean = 0, and standard deviation = 1.  

## K-Means Clustering Analysis
Development. The number of clusters to begin with will be decided by comparing the results of several different methods:

- The sum of squared error (SSE) scree plot  
- The `NbClust` function with method `kmeans`  
- [`factoextra::fviz_nbclust()`](https://www.datanovia.com/en/blog/types-of-clustering-methods-overview-and-quick-start-r-code/)  



# Decision points to address in the pre-registration 
**Decisions in bold**

1. Decide whether the outcome measure (anxiety) be STAI trait anxiety, or the STAI total score?  
    - **Trait anxiety**
2. Decide if the outcome measure should be continuous, or binary yes/no based on some cut-off (e.g. clinical)? Or should both be tried?  
    - **Will do continuous linear analysis first, then a secondary analysis with clinical cut-off of anxiety scores**
    - Need to define clinical cut-off. **Ask Tracy what they use**
        - STAI population mean of ~40 (go 1 standard deviation above population mean of 40)
3. Decide which algorithm(s) to apply (k-means, PCA, other)?  
    - **K-means with the number of clusters selected via examination of the elbow in the sum of squared error (SSE) scree plot and via testing of different numbers of clusters through cross-validation**
    - **I will use the `kmeans()` function in `R`, using the `nstart` option as recommended [here](https://www.r-statistics.com/2013/08/k-means-clustering-from-r-in-action/), which attempts multiple initial configurations and reports on the best one.**  
    - ["Clustering is more of a tool to help you explore a dataset, and should not always be used as an automatic method to classify data. Hence, you may not always deploy a clustering algorithm for real-world production scenario. They are often too unreliable, and a single clustering alone will not be able to give you all the information you can extract from a dataset."](https://www.datacamp.com/community/tutorials/k-means-clustering-r)  
    - ["it can only detect compact, hyperspherical clusters that are well separated."](https://www.sciencedirect.com/science/article/pii/S0957417412008767)  
    - [Methods for choosing the number of clusters](https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set)
    - Hierarchical clustering does not require knowing the number of clusters beforehand. Could be a good option.  
        -["a hierarchical cluster analysis was performed in order to determine the number of clusters for the K-means approach."](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4005932/)  
4. Identify the components of the attention bias measures to use in clustering (attention bias measures just means various components of the dot probe, right? E.g. reaction time.)  
    - **Will use those variables listed under "Available Dot Probe measures include:" that are not eliminated in pre-processing.**  
5. Decide how to deal with missing  values.  
    - **Remove the row.**  

# Dataset description

Available Dot Probe measures include:  

- `rt_neutral_nt`: Average RT on all neutral trials  
- `rt_threat_nt`: Average RT on all threat trials  
- `rt_baseline`: Average RT on baseline trials where two neutral faces appear and there is no competition for attention between threat and neutral faces; These trials appear randomly throughout the task  
- `rt_outliers`: # of trials considered to be outliers based on the following criteria (RTs faster than 150 ms or slower than 2000 ms; any trial RT that was +/- 3 SD from the person’s mean RT for that trial type)  
- `mean_pos`: mean of positive trial-level threat bias scores  
- `mean_neg`: mean of negative trial-level threat bias scores      
- `peak_pos`: highest positive trial-level threat bias score
- `peak_neg`: highest negative trial-level threat bias score           
- `variability`: absolute value of the distance across all trial-level threat bias scores / number of pairs 

# Analysis Plan, Part 1: K-means Clustering
## 1. Data cleaning

- Read in the data.  
- Use `janitor` to make the dataset names a consistent format.  
- Subset the data to retain only the dot probe measures (described above) and STAI Trait total score: `stai_trait_totalscore`  
- Subset the data into the set that will be used for the cluster analysis (all variables except STAI score)  
- There are no missing data as the dot probe measures exist for all participants who completed the task and who are included in this analysis. I therefore need not worry about biasing the results by omitting participants based on attention measures.  

## 2. Split data into development and holout, then training and testing

- 80/20 development/holdout split of the full data set.  
- 70/30 train/test split of the initial development set.  

## 3. Pre-processing of the train/test sets

- Check for and remove variables that are linear combinations of other variables.  
- Standardize variables since they vary in range (if using more than just RT).  
    - Using the `scale()` function, variables are scaled to mean = 0, sd = 1.  

## 4. K-means cluster analysis: development

### 4.a. Develop on the training data set  

- Identify the number of clusters 
    - Determine the optimal number of clusters to try with k-means by comparing the results of several different methods:
        - The sum of squared error (SSE) scree plot
        - The `NbClust` function with method `kmeans`
        - [`factoextra::fviz_nbclust()`](https://www.datanovia.com/en/blog/types-of-clustering-methods-overview-and-quick-start-r-code/)
        - Cross-validation with 10 folds

### 4.b. Apply the solution to the test data set  

- Repeat the above train/test steps until a satisfactory solution is reached.  

## 5. K-means cluster analysis: finalization
### 5.a. Pre-processing of the holdout data set

- Check for and remove variables that are linear combinations of other variables.  
- Standardize variables since they vary in range so they have mean = 0, sd = 1.  

### 5.b. Apply the finalized cluster analysis to the holdout data set  

- Evaluate cluster solution performance on the independent holdout data.  
    - ["Since the centroids provided by the function are based on standardized data, the `aggregate()` function is used along with the cluster memberships to determine variable means for each cluster in the original metric."](https://www.r-statistics.com/2013/08/k-means-clustering-from-r-in-action/)  
    
# Analysis Plan, Part 2: Between-subject analysis of variance (ANOVA)

- Use the data frame of dot probe measures and STAI Trait total score: `stai_trait_totalscore`  
- Remove rows with missing values on the `stai_trait_totalscore` using `na.omit()`  


`aov(STAI_anxiety ~ cluster_groups + Error(subject/cluster_groups), data=full_dataset)`







    
# Resources

- [Datacamp tutorial:](https://www.datacamp.com/community/tutorials/k-means-clustering-r) Describes basics of clustering & provides a tutorial of k-means clustering, including interpretation of output in R.    
- [A discussion of the relationship betweek K-means and PCA](https://stats.stackexchange.com/questions/183236/what-is-the-relation-between-k-means-clustering-and-pca)  
- [An overview of K means and hierarchical clustering, along with a good description of distance metrics](https://www.hackerearth.com/practice/machine-learning/machine-learning-algorithms/clustering-algorithms-evaluation-r/tutorial/)  
- [Von Luxburg, U. (2007). A tutorial on spectral clustering. Statistics and Computing, 17(4), 395–416. http://doi.org/10.1007/s11222-007-9033-z](https://arxiv.org/pdf/0711.0189.pdf): Preprint of a tutorial on spectral clustering by the Max Planck Institute   
- [Luxburg, U. V., Bousquet, O., & Belkin, M. (2005). Limits of spectral clustering. In Advances in neural information processing systems (pp. 857-864).](http://papers.nips.cc/paper/2692-limits-of-spectral-clustering.pdf): Preference for normalized over nonnormalized spectral clustering  
- Unsupervised learning: [Behavioral segmentation](https://www.datascience.com/blog/k-means-clustering) by attention bias measures (Dot Probe)**  
- [Spectral clustering R implementation](https://rpubs.com/nurakawa/spectral-clustering)
- [Drawbacks of K mean clustering](https://stats.stackexchange.com/questions/133656/how-to-understand-the-drawbacks-of-k-means)
- [Alternatives for segmenting noisy data](https://www.datascience.com/blog/k-means-alternatives)