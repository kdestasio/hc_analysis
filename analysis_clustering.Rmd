---
title: 'Hunter College Data: Clustering Analysis'
author: "Krista DeStasio"
date: "11/06/2018"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float: no
  pdf_document:
    toc: yes
    toc_depth: '3'
  word_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}
# Clear workspace
rm(list = ls()) 

# Set paths and working directory
working_dir = '~/Dropbox/collaborations/hunter_college/hc_analysis/'
path_datafile = paste0(working_dir, '/data/N=844_FINAL_Traditional metrics_Trial Level metrics_questionnaires (n=837)_6.16.18.xlsx')
setwd(working_dir)

# Install and load required packages
list.of.packages <- c('janitor', 'kernlab')
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])] 
if (length(new.packages)) install.packages(new.packages, repos = "http://cran.us.r-project.org")
lapply(list.of.packages, library, character.only = TRUE)

# Knit options
knitr::opts_chunk$set(echo = TRUE, eval = TRUE)
```

# Background information  

*Tracy writes:* "As I see it our first goal is testing whether distinct attention bias grouping emerge from the dot probe and questionnaire data using classification algorithms. Once these groups are identified, we can look at whether these are treatment-relevant subgroups (i.e., ABMT training is more effective for one group versus the other)."  

"examine the conditions under which ABMT efficacy is boosted or disrupted, and to identify individual differences that impact training gains"

A search for moderators that machine learning may be sensitive enough to detect.  

## Introduction
All analyses will be conducted using R (R Core Team, 2018). 


**Aim 1** is to identify whether meaningful subgroups emerge from the anxiety dot probe. I will compare the outcomes of a spectral clustering analysis (connectivity), a k-means cluster analysis (compactness), and a hierarchical clustering analysis to identify subgroups within the Anxiety Dot Probe measures as these approaches are well suited to numeric data. Hierarchical clustering methods, in contrast to k-means and spectral clustering, does not require a priori specification of number of clusters. Prior to clustering, dimension reduction will be done with principal components analysis to decresase overfitting and to make the models more inerpretable. The final solution will be selected based on visual inspection of the cluster outcomes, and based on the SSE for each solution. 

This analysis is done with the eventual goal of predicting treatment trajectories in an unrelated sample of Attention Bias Modification Training (ABMT) recipients. In that analysis, we will test whether cluster membership can predict the efficacy of ABMT (toward or away from threat) as measured by a post-ABMT re-application of the anxiety dot-probe.  

**Aim 2** is to test the hypothesis that bias toward threat during the anxiety dot probe correlates with greater trait anxiety as measured by State-Trait Anxiety Inventory (STAI) scores. To test this aim, I will run two separate analyses. The first is a linear regression with three threat bias scores entered as covariates: (1) threat bias ("average RTs for neutral probes in TN trials minus RTs for angry probes in TN trials"), (2) vigilance ("average RTs for neutral probes in NN trials minus RTs for angry probes in TN trials"), and (3) disengagement ("average RTs for neutral probes on TN trials minus RTs for neutral probes on NN trials").

`aov(STAI_anxiety ~ threat_bias*vigilance*disengagement)`

Second, I will test whether group membership, derived from the Aim 1 analysis, predicts STAI trait anxiety. Group membership will be entered as an independent variable into a between-subjects ANOVA with STAI trait anxiety scores as the dependent measure of interest. 

`aov(STAI_anxiety ~ cluster_groups + Error(subject/cluster_groups), data=full_dataset)`
 

## The data  
Dot Probe measures that will be included in the clustering analysis are:  

- `rt_neutral_nt`: Average RT on all neutral trials  
- `rt_threat_nt`: Average RT on all threat trials  
- `rt_baseline`: Average RT on baseline trials where two neutral faces appear and there is no competition for attention between threat and neutral faces; These trials appear randomly throughout the task  
- `rt_outliers`: # of trials considered to be outliers based on the following criteria (RTs faster than 150 ms or slower than 2000 ms; any trial RT that was +/- 3 SD from the person’s mean RT for that trial type)  
- `mean_pos`: mean of positive trial-level threat bias scores  
- `mean_neg`: mean of negative trial-level threat bias scores      
- `peak_pos`: highest positive trial-level threat bias score
- `peak_neg`: highest negative trial-level threat bias score           
- `variability`: absolute value of the distance across all trial-level threat bias scores / number of pairs

Variables for the regression analysis (Aim 2):   
- `threatbias_ERLAB`  
- `vigilance_ERLAB`  
- `disengage_ERLAB`  

## Data preprocessing 
### Outliers and missingness
Outliers were already removed from the data by our collaborators based on the percentage of trials that were answered correctly. Participants with an accuracy of .80 or greater are included in the dataset. There should be no initial missing data for the dot probe measures as the included metrics can be computed for anyone who completed the task.

### Colinearity and transformation
The dataset will be checked for variables that are linear combinations of other variables and those indicated will be removed. Variables will be standardized using the `scale()` function to mean = 0, and standard deviation = 1.  

# Code
## Data cleaning

- Use `janitor` to make the dataset names a consistent format.  
- Subset the data into the set that will be used for the cluster analysis (all variables except STAI score)  
- There are no missing data as the dot probe measures exist for all participants who completed the task and who are included in this analysis. I therefore need not worry about biasing the results by omitting participants based on attention measures.  

**Read in the data **
```{r, include=FALSE}
data_frame <- clean_names(readxl::read_excel(path_datafile)) # When ready to run, set to path_datafile
# Subset dot probe measures
data_matrix <- data_frame[,c(3:14, 22)]
row.names(data_matrix) <- data_frame$subject_id
data_matrix_aim1 <- subset(data_matrix, 
                           select = -c(threatbias_erlab, 
                                       vigilance_erlab, 
                                       disengage_erlab, 
                                       stai_trait_totalscore))
data_matrix_aim2 <- subset(data_matrix, 
                           select = c(threatbias_erlab, 
                                      vigilance_erlab, 
                                      disengage_erlab, 
                                      stai_trait_totalscore))
# Any missing data?
table(is.na(data_matrix_aim1))
```

## Pre-processing   
### Zero and near zero variance  

```{r Calculate variance metrics, include=FALSE}
# http://topepo.github.io/caret/pre-processing.html
# Frequency ratio & % of unique values
(nzv = caret::nearZeroVar(data_matrix_aim1, saveMetrics = TRUE))
```

### Linear dependencies
```{r Linear dependency, include=FALSE}
# Identify linear combinations
(comboInfo = caret::findLinearCombos(data_matrix_aim1))
# Display number of observations & features
dim(data_matrix_aim1)
```

### Normalization/Scaling

Clustering is sensitive to data being on different scales of measurement. To deal with this, check whether any of the features differ in scale. To do so, check whether means and standard deviations vary across the features, and if yes, scale them. Using the `scale()` function, variables are scaled to mean = 0, sd = 1.  

```{r normalization, include=FALSE}
colMeans(data_matrix_aim1) # means
apply(data_matrix_aim1, 2, sd) # standard deviation for each column
scaled_data <- scale(data_matrix_aim1) # scale the data

# Check that the data are scaled
round(colMeans(scaled_data), 2)
apply(scaled_data, 2, sd)
```

## Dimensionality reduction, Principal Components Analysis  
**Purpose: prevent overfitting of the data and improve interpretability**

```{r PCA}
set.seed(50)
pca_scaled <- prcomp(x = scaled_data)
summary(pca_scaled)
```

### Visualization
#### Biplot
```{r, echo=FALSE}
# Biplot
biplot(pca_scaled)
```

#### Scree plot
```{r, echo=FALSE}
# Get the proportion of variance
pca_var <- pca_scaled$sdev^2
prop_var_each <- pca_var / sum(pca_var)

par(mfrow = c(1,2)) 
# Plot the variance explained for each principal component
plot(prop_var_each, xlab = "Principal Component",
     ylab = "Proportion of Variance Explained",
     ylim = c(0,1), type = "b")

# Plot cumulative proportion of variance explained
plot(cumsum(prop_var_each), xlab = "Principal Component",
     ylab = "Cumulative Proportion of Variance Explained",
     ylim = c(0,1), type = "b")
```

### Conclusions from PCA

Either 2 or 4 components is reasonable and explain 80% and 95% of the variance, respectively.  

## K-means cluster analysis
### Development
Run k-means with 1 through 6 clusters. Record the total within-cluster sum of squares for each iteration with a different cluster number. Plot as scatterplots and as a scree plot. Look for the elbow in the scree plot to determine the number of clusters to use.  

```{r run kmeans, echo=FALSE, warning=FALSE}
set.seed(50)

# Initialize total within sum of squares error: wss
wss <- 0

# For 1 to 15 cluster centers
for (i in 1:15) {
  km.out <- kmeans(pca_scaled$x[,1:2], centers = i, nstart = 20)
  # Save total within sum of squares to wss variable
  wss[i] <- km.out$tot.withinss
}

# Scree plot
plot(1:15, wss, type = "b", 
     xlab = "Number of Clusters", 
     ylab = "Within groups sum of squares")

```

Select the final model
```{r examine kmeans results}
set.seed(50)
# Set k equal to the number of clusters corresponding to the elbow location
k <- 2
# fill in `pca_scaled$x[, : ]` with the number of clusters decided upon based on the PCA
kmeans_out_pca <- kmeans(pca_scaled$x[,1:2], centers = 2, nstart = 20) 
```
```{r, echo=FALSE}
par(mfrow = c(1,2)) 
# Plot the final model
plot(pca_scaled$x[,1:2],
     col = kmeans_out_pca$cluster,
     main = paste("k-means clustering,\nanxiety dot probe with", k, "clusters \nscaled data"),
     xlab = "var1", ylab = "var2")
plot(scaled_data,
     col = kmeans_out_pca$cluster,
     main = paste("k-means clustering,\n anxiety dot probe with", k, "clusters"),
     xlab = "var1", ylab = "var2")
```


- Evaluate cluster solution performance  
    - ["Since the centroids provided by the function are based on standardized data, the `aggregate()` function is used along with the cluster memberships to determine variable means for each cluster in the original metric."](https://www.r-statistics.com/2013/08/k-means-clustering-from-r-in-action/)  
    
```{r, echo=FALSE}
# Variable means  
aggregate(scaled_data, by = list(cluster = kmeans_out_pca$cluster), mean)
```

## Spectral Clustering
```{r}
set.seed(50)
spec_clust <- specc(pca_scaled$x[,1:2], centers = k) 
```

```{r, echo=FALSE}
par(mfrow = c(1,2)) 
plot(pca_scaled$x[,1:2], col = spec_clust, pch = 4)  # estimated classes
plot(scaled_data, col = spec_clust, pch = 4)  # estimated classes
```

```{r, echo=FALSE}
aggregate(scaled_data, by = list(cluster = spec_clust), mean)
```

## Hierarchical clustering

- `hclust()` function  

 Used when the number of clusters is not known ahead of time. There's top-down and bottom-up clustering. I will be using bottom-up clustering, which starts by assigning each point to it's own cluster, then iteratively combines them into fewer clusters based on distance between them until there's only 1 cluster. There are multiple ways to calculate the distance between observations. I will use euclidean distance. 

Create the first hierarchical clustering model.  

To determine the distance between clusters, one of 4 methods can be used:  
 (1) *Complete* - measures pairwaise similarity between clusters and uses the largest.  
 (2) *Single* - same as above, but uses smallest of similarities.  
 (3) *Average* - same as above, but uses average of similarities.  
 (4) *Centroid* - centroid of cluster 1 is calculated, centroid of cluster 2 is calculated and the distance between the 2 centroids is used.  
 
Complete and average tend to produce more balanced trees and are the most common.  

### Development
```{r hierarchical clustering}
set.seed(50)
# Need to use a dissimilarity structure with hclust()
hclust_complete <- hclust(dist(scaled_data, method = "euclidean"), method = 'complete') 
hclust_average <- hclust(dist(scaled_data, method = "euclidean"), method = 'average')
```

### Dendrogram plot

Determine the number of clusters wanted in the model. This is doen by specifying the height of the cut-off point in the dendrogram.
 
```{r, echo=FALSE}
#par(mfrow = c(1,2)) 
plot(hclust_complete, main = "Complete Linkage")
#plot(hclust_average, main = "Average Linkage")
hclust_complete_clusters <- cutree(hclust_average, k = 3)
#hclust_average_clusters <- cutree(hclust_average, k = 3)
```

Despite placing the cut at 3 clusters, it's really 2 since one cluster resulting from the first split has only one data point in.  

## Compare models
```{r, echo=FALSE}
table(kmeans_out_pca$cluster, hclust_complete_clusters)
table(spec_clust, hclust_complete_clusters)
table(spec_clust, kmeans_out_pca$cluster)
```

```{r, echo=FALSE}
knitr::kable(aggregate(scaled_data, 
                       by = list(cluster = kmeans_out_pca$cluster), 
                       mean), 
             caption = "K-means Clustering Means")
knitr::kable(aggregate(scaled_data, 
                       by = list(cluster = spec_clust), 
                       mean), 
             caption = "Spectral Clustering Means")
knitr::kable(aggregate(scaled_data, 
                       by = list(cluster = hclust_complete_clusters), 
                       mean),
             caption = "Hierarchical Clustering Means")
```



    
# Analysis Plan, Aim 2: Between-subject analysis of variance (ANOVA) 
This doesn't need to be done right away. Will do cluster analysis first & send to HC, then get to this.

1. Decide whether the outcome measure (anxiety) be STAI trait anxiety, or the STAI total score?  
    - **Trait anxiety**
2. Decide if the outcome measure should be continuous, or binary yes/no based on some cut-off (e.g. clinical)? Or should both be tried?  
    - **Will do continuous linear analysis first, then a secondary analysis with clinical cut-off of anxiety scores**
    - Need to define clinical cut-off. **Ask Tracy what they use**
        - STAI population mean of ~40 (go 1 standard deviation above population mean of 40)

- Use the data frame of dot probe measures and STAI Trait total score: `stai_trait_totalscore`  
- Remove rows with missing values on the `stai_trait_totalscore` using `na.omit()`  


`aov(STAI_anxiety ~ cluster_groups + Error(subject/cluster_groups), data=full_dataset)`




# General notes 
    - ["Clustering is more of a tool to help you explore a dataset, and should not always be used as an automatic method to classify data. Hence, you may not always deploy a clustering algorithm for real-world production scenario. They are often too unreliable, and a single clustering alone will not be able to give you all the information you can extract from a dataset."](https://www.datacamp.com/community/tutorials/k-means-clustering-r)  
    - [Methods for choosing the number of clusters](https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set)
    - Hierarchical clustering does not require knowing the number of clusters beforehand. Could be a good option.  
        -["a hierarchical cluster analysis was performed in order to determine the number of clusters for the K-means approach."](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4005932/)  


    
# Resources

- [Datacamp tutorial:](https://www.datacamp.com/community/tutorials/k-means-clustering-r) Describes basics of clustering & provides a tutorial of k-means clustering, including interpretation of output in R.    
- [A discussion of the relationship betweek K-means and PCA](https://stats.stackexchange.com/questions/183236/what-is-the-relation-between-k-means-clustering-and-pca)  
- [An overview of K means and hierarchical clustering, along with a good description of distance metrics](https://www.hackerearth.com/practice/machine-learning/machine-learning-algorithms/clustering-algorithms-evaluation-r/tutorial/)  
- [Von Luxburg, U. (2007). A tutorial on spectral clustering. Statistics and Computing, 17(4), 395–416. http://doi.org/10.1007/s11222-007-9033-z](https://arxiv.org/pdf/0711.0189.pdf): Preprint of a tutorial on spectral clustering by the Max Planck Institute   
- [Luxburg, U. V., Bousquet, O., & Belkin, M. (2005). Limits of spectral clustering. In Advances in neural information processing systems (pp. 857-864).](http://papers.nips.cc/paper/2692-limits-of-spectral-clustering.pdf): Preference for normalized over nonnormalized spectral clustering  
- Unsupervised learning: [Behavioral segmentation](https://www.datascience.com/blog/k-means-clustering) by attention bias measures (Dot Probe)**  
- [Spectral clustering R implementation](https://rpubs.com/nurakawa/spectral-clustering)
- [Drawbacks of K mean clustering](https://stats.stackexchange.com/questions/133656/how-to-understand-the-drawbacks-of-k-means)
- [Alternatives for segmenting noisy data](https://www.datascience.com/blog/k-means-alternatives)

