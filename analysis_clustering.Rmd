---
title: 'Hunter College Data: Clustering Analysis'
author: "Krista DeStasio"
date: "11/06/2018"
output: 
  html_document:
    toc: yes
    toc_depth: 3
    toc_float: no
---

```{r setup, include=FALSE}
# Clear workspace
rm(list = ls()) 

# Set paths and working directory
working_dir = '~/Dropbox/collaborations/hunter_college/hc_analysis/'
path_datafile = paste0(working_dir, '/data/N=844_FINAL_Traditional metrics_Trial Level metrics_questionnaires (n=837)_6.16.18.xlsx')
setwd(working_dir)

# Install and load required packages
list.of.packages <- c('janitor')
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])] 
if (length(new.packages)) install.packages(new.packages, repos = "http://cran.us.r-project.org")
lapply(list.of.packages, library, character.only = TRUE)

# Knit options
knitr::opts_chunk$set(echo = TRUE)
```
# Feedback from demo
**Suggestions**
- if have really high error (if the groups don't generalize well training to test) then what's the plan. Going to use different clustering algorithm? (random walk? classification and regression tree?) Network analysis tutorial from data science.
- What other unsupervised learning methods might work?  
- What is the metric of how well it's doing?  
- Identify ANOVA error term. See https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-how-can-i-determine-the-correct-error-term-in-an-anova/


# Purpose

**Motivation**: *Tracy writes:* "As I see it our first goal is testing whether distinct attention bias grouping emerge from the dot probe and questionnaire data using classification algorithms. Once these groups are identified, we can look at whether these are treatment-relevant subgroups (i.e., ABMT training is more effective for one group versus the other)."  

"examine the conditions under which ABMT efficacy is boosted or disrupted, and to identify individual differences that impact training gains"

A search for moderators that machine learning may be sensitive enough to detect.  

**Unsupervised learning: [Behavioral segmentation](https://www.datascience.com/blog/k-means-clustering) by attention bias measures (Dot Probe)**  

The primary purpose is to identify meaningful sub-groups in the anxiety dot probe. Once groups are defined, they will be entered into a within-subjects ANOVA to test whether cluster membership relates to anxiety as measured by the STAI. This is done with the eventual goal of predicting treatment trajectories in an unrelated sample of ABMT recipients.  

Because I want to use the clusters as a variable in the ANOVA, I will use hard clustering algorithms that assign each data point to a single cluster. I will start with a spectral clustering analysis.

k  means cluster analysis as this approach is well suited to numeric data. The success of the clustering algorithms will be decided subjectively based on the distance metrics and a plot of the clustering solution. I will try to balance the number of clusters and within-cluster varience. If a satisfactory solution cannot be derived with k means clustering, I will try [spectral clustering](http://www.di.fc.ul.pt/~jpn/r/spectralclustering/spectralclustering.html)


# Decision points to address in the pre-registration 
**Decisions in bold**

1. Decide whether the outcome measure (anxiety) be STAI trait anxiety, or the STAI total score?  
    - **Trait anxiety**
2. Decide if the outcome measure should be continuous, or binary yes/no based on some cut-off (e.g. clinical)? Or should both be tried?  
    - **Will do continuous linear analysis first, then a secondary analysis with clinical cut-off of anxiety scores**
    - Need to define clinical cut-off. **Ask Tracy what they use**
3. Decide which algorithm(s) to apply (k-means, PCA, other)?  
    - **K-means with the number of clusters selected via examination of the elbow in the sum of squared error (SSE) scree plot and via testing of different numbers of clusters through cross-validation**
    - **I will use the `kmeans()` function in `R`, using the `nstart` option as recommended [here](https://www.r-statistics.com/2013/08/k-means-clustering-from-r-in-action/), which attempts multiple initial configurations and reports on the best one.**  
    - ["Clustering is more of a tool to help you explore a dataset, and should not always be used as an automatic method to classify data. Hence, you may not always deploy a clustering algorithm for real-world production scenario. They are often too unreliable, and a single clustering alone will not be able to give you all the information you can extract from a dataset."](https://www.datacamp.com/community/tutorials/k-means-clustering-r)  
    - ["it can only detect compact, hyperspherical clusters that are well separated."](https://www.sciencedirect.com/science/article/pii/S0957417412008767)  
    - [Methods for choosing the number of clusters](https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set)
    - Hierarchical clustering does not require knowing the number of clusters beforehand. Could be a good option.  
        -["a hierarchical cluster analysis was performed in order to determine the number of clusters for the K-means approach."](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4005932/)  
4. Identify the components of the attention bias measures to use in clustering (attention bias measures just means various components of the dot probe, right? E.g. reaction time.)  
    - **Will use those variables listed under "Available Dot Probe measures include:" that are not eliminated in pre-processing.**  
5. Decide how to deal with missing  values.  
    - **Remove the row.**  

# Dataset description

Available Dot Probe measures include:  

- `rt_neutral_nt`: Average RT on all neutral trials  
- `rt_threat_nt`: Average RT on all threat trials  
- `rt_baseline`: Average RT on baseline trials where two neutral faces appear and there is no competition for attention between threat and neutral faces; These trials appear randomly throughout the task  
- `rt_outliers`: # of trials considered to be outliers based on the following criteria (RTs faster than 150 ms or slower than 2000 ms; any trial RT that was +/- 3 SD from the person’s mean RT for that trial type)  
- `mean_pos`: mean of positive trial-level threat bias scores  
- `mean_neg`: mean of negative trial-level threat bias scores      
- `peak_pos`: highest positive trial-level threat bias score
- `peak_neg`: highest negative trial-level threat bias score           
- `variability`: absolute value of the distance across all trial-level threat bias scores / number of pairs 

# Analysis Plan, Part 1: K-means Clustering
## 1. Data cleaning

- Read in the data.  
- Use `janitor` to make the dataset names a consistent format.  
- Subset the data to retain only the dot probe measures (described above) and STAI Trait total score: `stai_trait_totalscore`  
- Subset the data into the set that will be used for the cluster analysis (all variables except STAI score)  
- There are no missing data as the dot probe measures exist for all participants who completed the task and who are included in this analysis. I therefore need not worry about biasing the results by omitting participants based on attention measures.  

## 2. Split data into development and holout, then training and testing

- 80/20 development/holdout split of the full data set.  
- 70/30 train/test split of the initial development set.  

## 3. Pre-processing of the train/test sets

- Check for and remove variables that are linear combinations of other variables.  
- Standardize variables since they vary in range (if using more than just RT).  
    - Using the `scale()` function, variables are scaled to mean = 0, sd = 1.  

## 4. K-means cluster analysis: development

### 4.a. Develop on the training data set  

- Identify the number of clusters 
    - Determine the optimal number of clusters to try with k-means by comparing the results of several different methods:
        - The sum of squared error (SSE) scree plot
        - The `NbClust` function with method `kmeans`
        - [`factoextra::fviz_nbclust()`](https://www.datanovia.com/en/blog/types-of-clustering-methods-overview-and-quick-start-r-code/)
        - Cross-validation with 10 folds

### 4.b. Apply the solution to the test data set  

- Repeat the above train/test steps until a satisfactory solution is reached.  

## 5. K-means cluster analysis: finalization
### 5.a. Pre-processing of the holdout data set

- Check for and remove variables that are linear combinations of other variables.  
- Standardize variables since they vary in range so they have mean = 0, sd = 1.  

### 5.b. Apply the finalized cluster analysis to the holdout data set  

- Evaluate cluster solution performance on the independent holdout data.  
    - ["Since the centroids provided by the function are based on standardized data, the `aggregate()` function is used along with the cluster memberships to determine variable means for each cluster in the original metric."](https://www.r-statistics.com/2013/08/k-means-clustering-from-r-in-action/)  
    
# Analysis Plan, Part 2: Between-subject analysis of variance (ANOVA)

- Use the data frame of dot probe measures and STAI Trait total score: `stai_trait_totalscore`  
- Remove rows with missing values on the `stai_trait_totalscore` using `na.omit()`  


`aov(STAI_anxiety ~ cluster_groups + Error(subject/cluster_groups), data=full_dataset)`







    
# Resources

- [Datacamp tutorial:](https://www.datacamp.com/community/tutorials/k-means-clustering-r) Describes basics of clustering & provides a tutorial of k-means clustering, including interpretation of output in R.    
- [A discussion of the relationship betweek K-means and PCA](https://stats.stackexchange.com/questions/183236/what-is-the-relation-between-k-means-clustering-and-pca)  
- [An overview of K means and hierarchical clustering, along with a good description of distance metrics](https://www.hackerearth.com/practice/machine-learning/machine-learning-algorithms/clustering-algorithms-evaluation-r/tutorial/)  
- [Von Luxburg, U. (2007). A tutorial on spectral clustering. Statistics and Computing, 17(4), 395–416. http://doi.org/10.1007/s11222-007-9033-z](https://arxiv.org/pdf/0711.0189.pdf): Preprint of a tutorial on spectral clustering by the Max Planck Institute   
- [Luxburg, U. V., Bousquet, O., & Belkin, M. (2005). Limits of spectral clustering. In Advances in neural information processing systems (pp. 857-864).](http://papers.nips.cc/paper/2692-limits-of-spectral-clustering.pdf): Preference for normalized over nonnormalized spectral clustering  
